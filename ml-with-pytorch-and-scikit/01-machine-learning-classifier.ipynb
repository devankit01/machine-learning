{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet performs classification using the Perceptron model on the Iris dataset. Here's a breakdown:\n",
    "\n",
    "1. **Loading the Iris dataset**:\n",
    "   - The Iris dataset is a popular dataset for machine learning tasks. It contains measurements of iris flowers, categorized into three species.\n",
    "   - `load_iris()` function loads the Iris dataset, and `iris.data` contains the features (sepal length, sepal width, petal length, petal width), while `iris.target` contains the target labels (species).\n",
    "\n",
    "2. **Splitting the dataset**:\n",
    "   - `train_test_split()` function splits the dataset into training and testing sets.\n",
    "   - It assigns 80% of the data to training (`X_train`, `y_train`) and 20% to testing (`X_test`, `y_test`).\n",
    "\n",
    "3. **Feature scaling with StandardScaler**:\n",
    "   - `StandardScaler` is used to standardize the features by removing the mean and scaling to unit variance.\n",
    "   - `scaler.fit_transform(X_train)` computes the mean and standard deviation from the training data and then scales the training features.\n",
    "   - `scaler.transform(X_test)` applies the same transformation to the testing features using the parameters learned from the training data.\n",
    "\n",
    "4. **Initializing and training the Perceptron model**:\n",
    "   - `Perceptron` is a simple linear classifier that learns weights for each feature to make predictions.\n",
    "   - `perceptron = Perceptron(max_iter=1000, random_state=42)` initializes the Perceptron model with a maximum of 1000 iterations and a random seed for reproducibility.\n",
    "   - `perceptron.fit(X_train_scaled, y_train)` trains the Perceptron model on the scaled training data.\n",
    "\n",
    "5. **Making predictions**:\n",
    "   - `perceptron.predict(X_test_scaled)` predicts the target labels for the scaled testing data.\n",
    "\n",
    "6. **Evaluating the model**:\n",
    "   - `accuracy_score(y_test, y_pred)` calculates the accuracy of the model by comparing the predicted labels (`y_pred`) with the actual labels (`y_test`).\n",
    "   - The accuracy score is printed out as \"Accuracy\".\n",
    "\n",
    "Overall, this code demonstrates a simple workflow for training a Perceptron model on the Iris dataset, including preprocessing with feature scaling and evaluating model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron  # Import the Perceptron classifier\n",
    "from sklearn.datasets import load_iris  # Import the iris dataset\n",
    "from sklearn.model_selection import train_test_split  # Import train_test_split function\n",
    "from sklearn.metrics import accuracy_score  # Import accuracy_score function\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train: Training features, X_test: Testing features, y_train: Training labels, y_test: Testing labels\n",
    "# test_size=0.2: 20% of the data will be used for testing, random_state=42: Random seed for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Initialize and train the Perceptron model\n",
    "# max_iter=1000: Maximum number of iterations to converge, random_state=42: Random seed for reproducibility\n",
    "perceptron = Perceptron(max_iter=1000, random_state=42)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# Compare the predicted labels (y_pred) with the actual labels (y_test) and calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the Perceptron model\n",
    "perceptron = Perceptron(max_iter=1000, random_state=42)\n",
    "perceptron.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = perceptron.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
